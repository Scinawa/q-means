{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Means and the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we study the performances of Q-means algorithm on the MNIST dataset. Specifically, since q-means reduces to the classical algorithm \\delta-k-means we just tested the performance of \\delta-k-means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import sklearn as sk\n",
    "from mnist import MNIST\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "\n",
    "\n",
    "mndata = MNIST('/home/scinawa/workspace/hackedkit/python-mnist/data')\n",
    "mndata = MNIST('/home/scinawa/workspace/hackedkit/python-mnist/data')\n",
    "X_origin, y = mndata.load_training()\n",
    "X_test_origin, y_test = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data in memory and perform LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scinawa/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/scinawa/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "#X = digits.data / digits.data.max()\n",
    "#y = digits.target\n",
    "\n",
    "y = np.array(y)\n",
    "y_test = np.array(y_test)\n",
    "X_origin = np.array(X_origin)\n",
    "X_test_origin = np.array(X_test_origin)\n",
    "\n",
    "#X = sk.preprocessing.normalize(X)\n",
    "#dimred = PCA(n_components=35)\n",
    "dimred = LinearDiscriminantAnalysis()\n",
    "\n",
    "X = dimred.fit_transform(X_origin, y)\n",
    "X_test = dimred.transform(X_test_origin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing that kmeans indeed gives good values for the predictions.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_labels(predicted, correct):\n",
    "    labels_regular = np.zeros_like(correct)\n",
    "    for i in np.unique(correct):\n",
    "        #pdb.set_trace()\n",
    "        mask = (predicted == i)\n",
    "        labels_regular[mask] = mode(correct[mask])[0]\n",
    "    return labels_regular\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0, max_iter=10).fit(X)\n",
    "predicted_ = kmeans.predict(X_test)\n",
    "import pdb\n",
    "#pdb.set_trace()\n",
    "\n",
    "labels = find_labels(predicted_, y_test)\n",
    "\n",
    "\n",
    "print(\"The accuracy score of k-means after PCA is {:.3}%\".format(accuracy_score(y_test, predicted)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's measure the value of Z on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = sklearn.metrics.pairwise.pairwise_distances(X, kmeans.cluster_centers_)\n",
    "Z = max(np.ndarray.flatten(pd))\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_with_delta(X,centers,delta): #give X (points) and centers: 2 numpy arrays\n",
    "    labels = []\n",
    "    count = 0 #to count the number of times we chose a random center\n",
    "    for dist_array in pairwise_distances(X,centers): #dist_array is the array of distances between on element Xi of X and each cluster! \n",
    "        mindist = np.min(dist_array) #distance between Xi and its closest clusters\n",
    "        normalmin = [np.argmin(dist_array)] # index of the clusters closest to Xi\n",
    "        close_dist = set([dist for dist in dist_array if abs(dist-mindist)<delta]) #array of all distance of dist_array if they are delta-close to mindist \n",
    "        deltamin = [i for i, item in enumerate(dist_array) if item in close_dist] #index of delta-close centers \n",
    "        deltachoice = random.choice(deltamin) #choose randomly one of the delta-close centers\n",
    "        labels.append(deltachoice)\n",
    "        if deltamin!=normalmin:\n",
    "            count+=1\n",
    "    #print(\"DELTA K-MEANS: %d random choices of centers over %d\"%(count,len(X)))\n",
    "    return np.array(labels),count\n",
    "\n",
    "def label_regular(X,centers):\n",
    "    return pairwise_distances_argmin(X,centers)\n",
    "\n",
    "def lossfunction(X,labels,centers):\n",
    "    N = len(X)\n",
    "    loss = 1/np.sqrt(N)*np.sum([np.linalg.norm(X[i]-centers[labels[i]]) for i in range(N)])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the two implementation of k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters_regular(X, n_clusters, threshold, iterations=None):\n",
    "    # 1. Randomly choose clusters\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    i = rng.permutation(X.shape[0])[:n_clusters]\n",
    "    centers = X[i]\n",
    "    step = 0\n",
    "    loss = []\n",
    "    \n",
    "    while True:\n",
    "        step+=1\n",
    "        #print(\"step: {}\".format(step))\n",
    "        # 2a. Assign labels based on closest center\n",
    "        labels = pairwise_distances_argmin(X, centers) #REGULAR KMEANS\n",
    "        \n",
    "        # 2b. Find new centers from means of points\n",
    "        new_centers = np.array([X[labels == i].mean(0) for i in range(n_clusters)])\n",
    "        loss_step = lossfunction(X,labels,new_centers)\n",
    "        loss.append(loss_step)\n",
    "        #if step==1:\n",
    "            #print(\"step: {}\".format(step))\n",
    "            #plot_regular_clusters(X,labels,loss)\n",
    "        \n",
    "        if step>1:\n",
    "            \n",
    "            #if step%2==0:\n",
    "                #print(\"step: {}\".format(step))\n",
    "                #print(\"loss_step: {}\".format(loss_step))\n",
    "                #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                #plot_regular_clusters(X,labels,loss)\n",
    "                \n",
    "            # 2c. Check for convergence //!!\\\\change for threshold on Loss\n",
    "            if iterations == None:\n",
    "                if abs(loss_step - loss[-2])<threshold:\n",
    "                    #print(\"loss_step - loss[-2] = \"+str(loss_step)+\" - \"+str(loss[-2])+\" = \"+str(loss_step - loss[-2]))\n",
    "                    #print(\"step: {}\".format(step))\n",
    "                    #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                    #plot_regular_clusters(X,labels,loss)\n",
    "                    break                   \n",
    "            else:\n",
    "                if step == iterations:\n",
    "                    #print(\"END OF ITERATIONS\")\n",
    "                    #print(\"loss_step - loss[-2] = \"+str(loss_step)+\" - \"+str(loss[-2])+\" = \"+str(loss_step - loss[-2]))\n",
    "                    #print(\"step: {}\".format(step))\n",
    "                    #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                    #plot_regular_clusters(X,labels,loss)\n",
    "                    break                    \n",
    "        centers = new_centers\n",
    "    return centers, labels\n",
    "\n",
    "\n",
    "def find_clusters_delta(X, n_clusters, delta, threshold, iterations=None):\n",
    "    # 1. Randomly choose clusters\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    i = rng.permutation(X.shape[0])[:n_clusters]\n",
    "    centers = X[i]\n",
    "    step = 0\n",
    "    random_choices = []\n",
    "    loss = []\n",
    "    \n",
    "    while True:\n",
    "        step+=1\n",
    "        \n",
    "        # 2a. Assign labels based on closest center\n",
    "        labels, count = label_with_delta(X,centers,delta) #DELTA KMEANS\n",
    "        random_choices.append(count)\n",
    "        \n",
    "        \n",
    "        # 2b. Find new centers from means of points\n",
    "        new_centers = np.array([X[labels == i].mean(0) for i in range(n_clusters)])\n",
    "        loss_step = lossfunction(X,labels,new_centers)\n",
    "        loss.append(loss_step)\n",
    "        \n",
    "        #if step==1:\n",
    "            #print(\"step: {}\".format(step))\n",
    "            #plot_delta_clusters(X,labels,random_choices,loss)\n",
    "\n",
    "        if step>1:\n",
    "            \n",
    "            #if step%2==0:\n",
    "                #print(\"step: {}\".format(step))\n",
    "                #print(\"loss_step: {}\".format(loss_step))\n",
    "                #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                #plot_delta_clusters(X,labels,random_choices,loss)\n",
    "\n",
    "\n",
    "            # 2c. Check for convergence //!!\\\\change for threshold on Loss\n",
    "            if iterations == None:\n",
    "                \n",
    "                if abs(loss_step - loss[-2])<threshold:\n",
    "                    #print(\"loss_step - loss[-2] = \"+str(loss_step)+\" - \"+str(loss[-2])+\" = \"+str(loss_step - loss[-2]))\n",
    "                    #print(\"step: {}\".format(step))\n",
    "                    #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                    #plot_delta_clusters(X,labels,random_choices,loss)\n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                if step == iterations:\n",
    "                    #print(\"END OF ITERATIONS\")\n",
    "                    #print(\"loss_step - loss[-2] = \"+str(loss_step)+\" - \"+str(loss[-2])+\" = \"+str(loss_step - loss[-2]))\n",
    "                    #print(\"step: {}\".format(step))\n",
    "                    #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                    #plot_delta_clusters(X,labels,random_choices,loss)\n",
    "                    break\n",
    "                \n",
    "        centers = new_centers\n",
    "\n",
    "    return centers, labels, random_choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The experiment: measuring accuracy for k-means and d-means\n",
    "For some number of iteration we measure the accuracy of our classifier, removing the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations_set = np.linspace(3, 30, 27, dtype=int)\n",
    "results_kmeans = []\n",
    "results_dmeans = []\n",
    "results_dmeans_2 = []\n",
    "results_kmeans_original = []\n",
    "results_dmeans_original = []\n",
    "\n",
    "\n",
    "threshold = 0.000001 #useless\n",
    "delta = 0.3\n",
    "delta_2 = 0.4\n",
    "delta_original = 0.1\n",
    "\n",
    "n_clusters = 10\n",
    "\n",
    "for iterations in iterations_set:\n",
    "    print(\"Iteration %d \"%iterations)\n",
    "    \n",
    "    accuracy_set_kmeans = []\n",
    "    accuracy_set_dmeans = []\n",
    "    accuracy_set_dmeans_2 = []\n",
    "    accuracy_set_kmeans_original = []\n",
    "    accuracy_set_dmeans_original = []\n",
    "    \n",
    "    for sample in range(4):\n",
    "        rseed=random.randint(10,50) #random initialization must be the same for comparing regular and delta kmeans\n",
    "        \n",
    "        #KMEANS\n",
    "        centroids_regular, labels_regular_ = find_clusters_regular(X, n_clusters, threshold, iterations=iterations)\n",
    "        accuracy_set_kmeans.append(accuracy_score(y,find_labels(labels_regular_) ))\n",
    "        \n",
    "        \n",
    "        #DMEANS\n",
    "        centroids_delta, labels_delta_, _ = find_clusters_delta(X, n_clusters, delta, threshold, iterations=iterations)\n",
    "        accuracy_set_dmeans.append(accuracy_score(y,find_labels(labels_delta_)))  \n",
    "        \n",
    "        \n",
    "        # DMEANS 2\n",
    "        centroids_delta_2, labels_delta_2_, _ = find_clusters_delta(X, n_clusters, delta_2, threshold, iterations=iterations)       \n",
    "        accuracy_set_dmeans_2.append(accuracy_score(y,find_labels(labels_delta_2_)))  \n",
    "        \n",
    "        \n",
    "        # KMEANS (No DR)\n",
    "        centroids_delta_2, labels_delta_2_, _ = find_cluster_regular(X_original, n_clusters, delta_2, threshold, iterations=iterations)       \n",
    "        accuracy_set_kmeans_original.append(accuracy_score(y,find_labels(labels_delta_2_)))  \n",
    "        \n",
    "        \n",
    "        # DMEANS (No DR)\n",
    "        centroids_delta_2, labels_delta_2_, _ = find_clusters_delta(X_original, n_clusters, delta_original, threshold, iterations=iterations)       \n",
    "        accuracy_set_dmeans_original.append(accuracy_score(y,find_labels(labels_delta_2_)))  \n",
    "        \n",
    "        \n",
    "        print(\"Execution {} | (PCA) k-means = {:.2%} - q-means = {:.2%} q-means_2 = {:.2%} - (no-dr) k-means {:.2%}  - (no-dr) d-means {:.2%} \".format(sample, accuracy_score(y,labels_regular), accuracy_score(y,labels_delta),accuracy_score(y,labels_delta_2)))    \n",
    "\n",
    "    results_kmeans.append(np.average(accuracy_set_kmeans))\n",
    "    results_dmeans.append(np.average(accuracy_set_dmeans))\n",
    "    results_dmeans_2.append(np.average(accuracy_set_dmeans_2))\n",
    "    results_kmeans_original.append(np.average(accuracy_set_kmeans_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We test delta KMEANS on the NON DR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we plot the accuracy for all the experiments on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_set = np.insert(iterations_set, 0,0)\n",
    "import pdb\n",
    "pdb.set_trace\n",
    "\n",
    "print(len(iterations_set))\n",
    "print(iterations_set)\n",
    "print(\"porcodio\")\n",
    "\n",
    "results_kmeans = [0] + results_kmeans\n",
    "results_dmeans = [0] + results_dmeans\n",
    "results_dmeans_2 = [0] + results_dmeans_2\n",
    "results_kmeans_original = [0] + results_kmeans_original\n",
    "\n",
    "\n",
    "\n",
    "print(results_kmeans)\n",
    "print(results_dmeans)\n",
    "print(results_dmeans_2)\n",
    "print(results_kmeans_original)\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "#pdb.set_trace()\n",
    "\n",
    "plot_k = plt.plot(iterations_set,results_kmeans,'b', label=\"(LDA) k-means\")\n",
    "plot_d = plt.plot(iterations_set,results_dmeans,'r', label=\"(LDA) q-means (\\delta = 0.4)\")\n",
    "plot_d_2 = plt.plot(iterations_set,results_dmeans_2,'y', label=\"(LDA) q-means (\\delta = 0.3)\")\n",
    "plot_k_non_dr = plt.plot(iterations_set,results_kmeans_original,'y', label=\"k-means\")\n",
    "#plot_d_non_dr = plt.plot(iterations_set,results_dmeans_original,'y', label=\"\\delta-k-means\")\n",
    "\n",
    "\n",
    "#blue_line = mlines.Line2D(iterations_set, results_kmeans, color='#004c6d', marker='*', markersize=15, label='(LDA) k-means')\n",
    "#red_line = mlines.Line2D(iterations_set, results_dmeans, color='#7fc0cd', marker='*', markersize=15, label='(LDA) \\delta-k-means  0.3')\n",
    "#yellow_line = mlines.Line2D(iterations_set, results_dmeans_2, color='#e5ffff', marker='.', markersize=15, label='(LDA) \\delta-k-means 0.4')\n",
    "#green_line = mlines.Line2D(iterations_set, results_kmeans_original, color='#35ffff', marker='.', markersize=15, label='\\delta-k-means 0.5')\n",
    "\n",
    "\n",
    "plt.xlabel('Iterations ')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "\n",
    "plt.xlim(0, 37)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='lower right', ncol=1, shadow=True, fancybox=True ) #, labels=['kmeans', 'dmeans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
