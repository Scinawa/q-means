{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Means and the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we study the performances of Q-means algorithm on the MNIST dataset. Specifically, since q-means reduces to the classical algorithm \\delta-k-means we just tested the performance of \\delta-k-means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DMeans\n",
    "\n",
    "from mnist import MNIST\n",
    "\n",
    "import importlib\n",
    "importlib.reload(sk)\n",
    "\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('/home/scinawa/workspace/hackedkit/python-mnist/data')\n",
    "mndata = MNIST('/home/scinawa/workspace/hackedkit/python-mnist/data')\n",
    "X_origin, y = mndata.load_training()\n",
    "X_test_origin, y_test = mndata.load_testing()\n",
    "\n",
    "y = np.array(y)\n",
    "y_test = np.array(y_test)\n",
    "X_origin = np.array(X_origin)\n",
    "X_test_origin = np.array(X_test_origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data in memory and perform LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = digits.data / digits.data.max()\n",
    "#y = digits.target\n",
    "\n",
    "\n",
    "#X = sk.preprocessing.normalize(X)\n",
    "dimred = PCA(n_components=35)\n",
    "#dimred = LinearDiscriminantAnalysis()\n",
    "\n",
    "X = dimred.fit_transform(X_origin, y)\n",
    "X_test = dimred.transform(X_test_origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing that kmeans indeed gives good values for the predictions.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of k-means after PCA is 0.863%\n"
     ]
    }
   ],
   "source": [
    "def find_labels(predicted, correct):\n",
    "    labels_regular = np.zeros_like(correct)\n",
    "    for i in np.unique(correct):        \n",
    "        mask = (predicted == i)\n",
    "        labels_regular[mask] = mode(correct[mask])[0]\n",
    "    return labels_regular\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(X)\n",
    "predicted_ = kmeans.predict(X_test)\n",
    "labels = find_labels(predicted_, y_test)\n",
    "\n",
    "\n",
    "print(\"The accuracy score of k-means after PCA is {:.3}%\".format(accuracy_score(y_test, labels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of k-means before PCA is 0.595%\n"
     ]
    }
   ],
   "source": [
    "kmeans2 = KMeans(n_clusters=10, random_state=0).fit(X_origin)\n",
    "predicted_origin_= kmeans2.predict(X_test_origin)\n",
    "labels_origin = find_labels(predicted_origin_, y_test)\n",
    "\n",
    "print(\"The accuracy score of k-means before PCA is {:.3}%\".format(accuracy_score(y_test, labels_origin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's measure the value of Z on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898.0414442673764\n"
     ]
    }
   ],
   "source": [
    "norms = np.linalg.norm(X, axis=1)\n",
    "norms_cluster =np.linalg.norm(kmeans.cluster_centers_, axis=1)\n",
    "\n",
    "Z = max(norms)+max(norms_cluster)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The experiment: measuring accuracy for k-means and d-means\n",
    "For some number of iteration we measure the accuracy of our classifier, removing the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_labels(predicted, correct):\n",
    "    labels_regular = np.zeros_like(correct)\n",
    "    correct = np.array(correct)\n",
    "    for i in np.unique(correct):        \n",
    "        mask = (predicted == i)\n",
    "        labels_regular[mask] = mode(correct[mask])[0]\n",
    "    return labels_regular\n",
    "\n",
    "\n",
    "def accuracy_kmeans(X, n_cluster, iteration_number, X_test, y_test, rseed):\n",
    "    kmeans = KMeans(n_clusters=n_cluster, random_state=rseed, max_iter=iteration_number).fit(X)\n",
    "    \n",
    "    predicted_ = kmeans.predict(X_test)\n",
    "    labels = find_labels(predicted_, y_test)\n",
    "    \n",
    "    accuracy = accuracy_score(np.array(y_test), labels)\n",
    "    return accuracy\n",
    "\n",
    "def accuracy_dmeans(X, n_cluster, iteration_number, X_test, y_test, delta, rseed):\n",
    "    dmeans = DMeans(n_clusters=n_cluster, random_state=rseed, n_init=3, max_iter=iteration_number, delta=delta).fit(X)\n",
    "    \n",
    "    #import pdb\n",
    "    #pdb.set_trace()    \n",
    "    predicted_ = dmeans.predict(X_test)\n",
    "    labels = find_labels(predicted_, y_test)\n",
    "    \n",
    "    accuracy = accuracy_score(np.array(y_test), labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running clustering algos with max 2 iterations \n",
      " run 0 | (DR) k-means:58.51% - q-means:58.52% - q-means_2:58.53% | (no-DR) k-means:53.38% - d-means:53.38% \n"
     ]
    }
   ],
   "source": [
    "iterations_set = np.linspace(2, 30, 14, dtype=int)\n",
    "results_kmeans = []\n",
    "results_dmeans = []\n",
    "results_dmeans_2 = []\n",
    "results_kmeans_original = []\n",
    "results_dmeans_original = []\n",
    "\n",
    "delta = 0.3\n",
    "delta_2 = 1\n",
    "delta_original = 0.1\n",
    "\n",
    "n_clusters = 10\n",
    "\n",
    "for iterations in iterations_set:\n",
    "    print(\"Running clustering algos with max {} iterations \".format(iterations))\n",
    "    \n",
    "    accuracy_set_kmeans = []\n",
    "    accuracy_set_dmeans = []\n",
    "    accuracy_set_dmeans_2 = []\n",
    "    accuracy_set_kmeans_original = []\n",
    "    accuracy_set_dmeans_original = []\n",
    "    \n",
    "    for sample in range(2): # this iteration is useless since we have n_iter from sklearn\n",
    "        rseed=random.randint(10,50) #random initialization must be the same for comparing regular and delta kmeans\n",
    "        \n",
    "        #KMEANS\n",
    "        accuracy = accuracy_kmeans(X, n_clusters, iterations, X_test, y_test, rseed)\n",
    "        accuracy_set_kmeans.append(accuracy)\n",
    "\n",
    "        #DMEANS\n",
    "        accuracy = accuracy_dmeans(X, n_clusters, iterations, X_test, y_test, delta, rseed)\n",
    "        accuracy_set_dmeans.append(accuracy)  \n",
    "\n",
    "        # DMEANS 2\n",
    "        accuracy = accuracy_dmeans(X, n_clusters, iterations, X_test, y_test, delta_2, rseed)       \n",
    "        accuracy_set_dmeans_2.append(accuracy)  \n",
    "        \n",
    "        #KMEANS NO-DR\n",
    "        accuracy = accuracy_kmeans(X_origin, n_clusters, iterations, X_test_origin, y_test, rseed)\n",
    "        accuracy_set_kmeans_original.append(accuracy)\n",
    "        \n",
    "        # DMEANS NO-DR \n",
    "        accuracy = accuracy_dmeans(X_origin, n_clusters, iterations, X_test_origin, y_test, delta_original,rseed)       \n",
    "        accuracy_set_dmeans_original.append(accuracy)  \n",
    "        \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        print(\" run {} | (DR) k-means:{:.2%} - q-means:{:.2%} - q-means_2:{:.2%} | (no-DR) k-means:{:.2%} - d-means:{:.2%} \".format(         \n",
    "            sample, accuracy_set_kmeans[-1], accuracy_set_dmeans[-1], accuracy_set_dmeans_2[-1], accuracy_set_kmeans_original[-1], accuracy_set_dmeans_original[-1] ))    \n",
    "\n",
    "    results_kmeans.append(np.average(accuracy_set_kmeans))\n",
    "    results_dmeans.append(np.average(accuracy_set_dmeans))\n",
    "    results_dmeans_2.append(np.average(accuracy_set_dmeans_2))\n",
    "    results_kmeans_original.append(np.average(accuracy_set_kmeans_original))\n",
    "    results_dmeans_original.append(np.average(accuracy_set_dmeans_original))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we plot the accuracy for all the experiments on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_set = np.insert(iterations_set, 0,0)\n",
    "\n",
    "results_kmeans = [0] + results_kmeans\n",
    "results_dmeans = [0] + results_dmeans\n",
    "results_dmeans_2 = [0] + results_dmeans_2\n",
    "results_kmeans_original = [0] + results_kmeans_original\n",
    "\n",
    "\n",
    "\n",
    "print(results_kmeans)\n",
    "print(results_dmeans)\n",
    "print(results_dmeans_2)\n",
    "print(results_kmeans_original)\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "#pdb.set_trace()\n",
    "\n",
    "plot_k = plt.plot(iterations_set,results_kmeans,'#004c6d', label=\"(LDA) k-means\")\n",
    "plot_d = plt.plot(iterations_set,results_dmeans,'#7fc0cd', label=\"(LDA) q-means (\\delta = 0.4)\")\n",
    "plot_d_2 = plt.plot(iterations_set,results_dmeans_2,'#e5ffff', label=\"(LDA) q-means (\\delta = 0.3)\")\n",
    "plot_k_non_dr = plt.plot(iterations_set,results_kmeans_original,'#35ffff', label=\"k-means\")\n",
    "tplot_d_non_dr = plt.plot(iterations_set,results_dmeans_original,'#2fc0cd', label=\"\\delta-k-means\")\n",
    "\n",
    "\n",
    "#blue_line = mlines.Line2D(iterations_set, results_kmeans, color='#004c6d', marker='*', markersize=15, label='(LDA) k-means')\n",
    "#red_line = mlines.Line2D(iterations_set, results_dmeans, color='#7fc0cd', marker='*', markersize=15, label='(LDA) \\delta-k-means  0.3')\n",
    "#yellow_line = mlines.Line2D(iterations_set, results_dmeans_2, color='#e5ffff', marker='.', markersize=15, label='(LDA) \\delta-k-means 0.4')\n",
    "#green_line = mlines.Line2D(iterations_set, results_kmeans_original, color='#35ffff', marker='.', markersize=15, label='\\delta-k-means 0.5')\n",
    "\n",
    "\n",
    "plt.xlabel('Iterations ')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "\n",
    "plt.xlim(0, 37)\n",
    "plt.ylim(0.5, 1)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend(loc='lower right', ncol=1, shadow=True, fancybox=True ) #, labels=['kmeans', 'dmeans'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Other measure of good of clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook we compared other measure of performances between delta-k-means and k-means for a small enough value of delta.\n",
    "\n",
    "From http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_k_means(estimator, name, data):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=sample_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "data = scale(digits.data)\n",
    "delta = 0.8\n",
    "n_samples, n_features = data.shape\n",
    "n_digits = len(np.unique(digits.target))\n",
    "labels = digits.target\n",
    "\n",
    "\n",
    "print('init \\t\\t inertia \\t homo\\t compl\\t v-meas\\t ARI \\t AMI \\t silhouette')\n",
    "\n",
    "bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10, algorithm=\"full\"),\n",
    "                  name=\"k-means++\", data=data)\n",
    "\n",
    "bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10),\n",
    "                  name=\"random\", data=data)\n",
    "\n",
    "# in this case the seeding of the centers is deterministic, hence we run the\n",
    "# kmeans algorithm only once with n_init=1\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1), name=\"PCA-based\", data=data)\n",
    "\n",
    "print(30 * '=', \"D-means\", 30 * \"=\")\n",
    "\n",
    "\n",
    "bench_k_means(DMeans(init='k-means++', n_clusters=n_digits, n_init=10, delta=delta), name=\"d-means++\", data=data)\n",
    "\n",
    "bench_k_means(DMeans(init='random', n_clusters=n_digits, n_init=10, delta=delta), name=\"d-means random\", data=data)\n",
    "\n",
    "# in this case the seeding of the centers is deterministic, hence we run the\n",
    "# kmeans algorithm only once with n_init=1\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "bench_k_means(DMeans(init=pca.components_, n_clusters=n_digits, n_init=1, delta=delta), name=\"d-means PCA-based\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: implementation of delta-k-means (not ++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_with_delta(X,centers,delta): #give X (points) and centers: 2 numpy arrays\n",
    "    labels = []\n",
    "    count = 0 #to count the number of times we chose a random center\n",
    "    for dist_array in pairwise_distances(X,centers): #dist_array is the array of distances between on element Xi of X and each cluster! \n",
    "        mindist = np.min(dist_array) #distance between Xi and its closest clusters\n",
    "        normalmin = [np.argmin(dist_array)] # index of the clusters closest to Xi\n",
    "        close_dist = set([dist for dist in dist_array if abs(dist-mindist)<delta]) #array of all distance of dist_array if they are delta-close to mindist \n",
    "        deltamin = [i for i, item in enumerate(dist_array) if item in close_dist] #index of delta-close centers \n",
    "        deltachoice = random.choice(deltamin) #choose randomly one of the delta-close centers\n",
    "        labels.append(deltachoice)\n",
    "        if deltamin!=normalmin:\n",
    "            count+=1\n",
    "    #print(\"DELTA K-MEANS: %d random choices of centers over %d\"%(count,len(X)))\n",
    "    return np.array(labels),count\n",
    "\n",
    "def label_regular(X,centers):\n",
    "    return pairwise_distances_argmin(X,centers)\n",
    "\n",
    "def lossfunction(X,labels,centers):\n",
    "    N = len(X)\n",
    "    loss = 1/np.sqrt(N)*np.sum([np.linalg.norm(X[i]-centers[labels[i]]) for i in range(N)])\n",
    "    return loss\n",
    "\n",
    "\n",
    "def find_clusters_regular(X, n_clusters, threshold, iterations=None):\n",
    "    # 1. Randomly choose clusters\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    i = rng.permutation(X.shape[0])[:n_clusters]\n",
    "    centers = X[i]\n",
    "    step = 0\n",
    "    loss = []\n",
    "    \n",
    "    while True:\n",
    "        step+=1\n",
    "        #print(\"step: {}\".format(step))\n",
    "        # 2a. Assign labels based on closest center\n",
    "        labels = pairwise_distances_argmin(X, centers) #REGULAR KMEANS\n",
    "        \n",
    "        # 2b. Find new centers from means of points\n",
    "        new_centers = np.array([X[labels == i].mean(0) for i in range(n_clusters)])\n",
    "        loss_step = lossfunction(X,labels,new_centers)\n",
    "        loss.append(loss_step)\n",
    "        #if step==1:\n",
    "            #print(\"step: {}\".format(step))\n",
    "            #plot_regular_clusters(X,labels,loss)\n",
    "        \n",
    "        if step>1:\n",
    "            \n",
    "            #if step%2==0:\n",
    "                #print(\"step: {}\".format(step))\n",
    "                #print(\"loss_step: {}\".format(loss_step))\n",
    "                #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                #plot_regular_clusters(X,labels,loss)\n",
    "                \n",
    "            # 2c. Check for convergence //!!\\\\change for threshold on Loss\n",
    "            if iterations == None:\n",
    "                if abs(loss_step - loss[-2])<threshold:\n",
    "                    #print(\"loss_step - loss[-2] = \"+str(loss_step)+\" - \"+str(loss[-2])+\" = \"+str(loss_step - loss[-2]))\n",
    "                    #print(\"step: {}\".format(step))\n",
    "                    #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                    #plot_regular_clusters(X,labels,loss)\n",
    "                    break                   \n",
    "            else:\n",
    "                if step == iterations:\n",
    "                    #print(\"END OF ITERATIONS\")\n",
    "                    #print(\"loss_step - loss[-2] = \"+str(loss_step)+\" - \"+str(loss[-2])+\" = \"+str(loss_step - loss[-2]))\n",
    "                    #print(\"step: {}\".format(step))\n",
    "                    #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                    #plot_regular_clusters(X,labels,loss)\n",
    "                    break                    \n",
    "        centers = new_centers\n",
    "    return centers, labels\n",
    "\n",
    "\n",
    "def find_clusters_delta(X, n_clusters, delta, threshold, iterations=None):\n",
    "    # 1. Randomly choose clusters\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    i = rng.permutation(X.shape[0])[:n_clusters]\n",
    "    centers = X[i]\n",
    "    step = 0\n",
    "    random_choices = []\n",
    "    loss = []\n",
    "    \n",
    "    while True:\n",
    "        step+=1\n",
    "        \n",
    "        # 2a. Assign labels based on closest center\n",
    "        labels, count = label_with_delta(X,centers,delta) #DELTA KMEANS\n",
    "        random_choices.append(count)\n",
    "        \n",
    "        \n",
    "        # 2b. Find new centers from means of points\n",
    "        new_centers = np.array([X[labels == i].mean(0) for i in range(n_clusters)])\n",
    "        loss_step = lossfunction(X,labels,new_centers)\n",
    "        loss.append(loss_step)\n",
    "        \n",
    "        #if step==1:\n",
    "            #print(\"step: {}\".format(step))\n",
    "            #plot_delta_clusters(X,labels,random_choices,loss)\n",
    "\n",
    "        if step>1:\n",
    "            \n",
    "            #if step%2==0:\n",
    "                #print(\"step: {}\".format(step))\n",
    "                #print(\"loss_step: {}\".format(loss_step))\n",
    "                #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                #plot_delta_clusters(X,labels,random_choices,loss)\n",
    "\n",
    "\n",
    "            # 2c. Check for convergence //!!\\\\change for threshold on Loss\n",
    "            if iterations == None:\n",
    "                \n",
    "                if abs(loss_step - loss[-2])<threshold:\n",
    "                    #print(\"loss_step - loss[-2] = \"+str(loss_step)+\" - \"+str(loss[-2])+\" = \"+str(loss_step - loss[-2]))\n",
    "                    #print(\"step: {}\".format(step))\n",
    "                    #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                    #plot_delta_clusters(X,labels,random_choices,loss)\n",
    "                    break\n",
    "                    \n",
    "            else:\n",
    "                if step == iterations:\n",
    "                    #print(\"END OF ITERATIONS\")\n",
    "                    #print(\"loss_step - loss[-2] = \"+str(loss_step)+\" - \"+str(loss[-2])+\" = \"+str(loss_step - loss[-2]))\n",
    "                    #print(\"step: {}\".format(step))\n",
    "                    #print(\"LossDiff: {}\".format(abs(loss_step - loss[-2])))\n",
    "                    #plot_delta_clusters(X,labels,random_choices,loss)\n",
    "                    break\n",
    "                \n",
    "        centers = new_centers\n",
    "\n",
    "    return centers, labels, random_choices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
